\chapter{Introduction}

\section{Purpose}

The purpose of this Software Requirements Specification (SRS) document is to provide a comprehensive and detailed description of the ScholarFlow platform --- an AI-powered research paper collaboration hub designed to address critical inefficiencies in academic research workflows. This document establishes the functional and non-functional requirements, system constraints, and design considerations necessary for the successful development, implementation, and deployment of ScholarFlow.

\subsection{Document Scope}

This SRS serves multiple stakeholders:

\begin{itemize}
    \item \textbf{Development Team}: Provides architectural blueprints, technical specifications, and implementation guidelines for building ScholarFlow's multi-tier architecture (Next.js frontend, Express.js backend, PostgreSQL database).
    \item \textbf{Project Managers}: Defines project scope boundaries, feature prioritization frameworks (P0/P1/P2 tiers), and milestone acceptance criteria aligned with the 7-phase roadmap.
    \item \textbf{Quality Assurance Team}: Establishes testable requirements, performance benchmarks (sub-300ms search latency, 95\% AI accuracy), and validation criteria for feature acceptance.
    \item \textbf{Stakeholders \& Investors}: Demonstrates market validation through survey-backed insights (32 responses, 75\% need validation), competitive differentiation, and revenue model viability.
\end{itemize}

\subsection{Target Audience Demographics}

Based on comprehensive survey data from 32 respondents (students and faculty) across multiple universities:

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|l|p{8cm}|}
        \hline
        \textbf{Demographic}       & \textbf{Percentage} & \textbf{Strategic Implications}                                                                          \\
        \hline
        \textbf{Role}              &
        78.1\% Undergraduate       &
        Design for minimal learning curve; prioritize mobile responsiveness for on-the-go access; implement lightweight features for casual researchers.            \\
        \hline
        \textbf{Age}               &
        68.8\% Ages 22-25          &
        Gen-Z digital natives expect modern UI/UX (dark mode, glassmorphism), seamless OAuth (Google/GitHub), and instant AI-powered insights.                      \\
        \hline
        \textbf{Field}             &
        34.4\% Computer Science    &
        Tech-savvy users will demand API access, browser extensions, Overleaf integration, and advanced features like semantic search and AI chat.                  \\
        \hline
        \textbf{Reading Frequency} &
        43.8\% Rarely Read         &
        Dual-persona design required: lightweight interface for casual users, power features (annotations, collections, AI summaries) for daily researchers (25\%). \\
        \hline
        \textbf{Institution}       &
        60\% UIU Concentration     &
        Ideal beta testing ground; leverage UIU cohort for early feedback loops, feature validation, and organic campus network effects.                            \\
        \hline
    \end{tabular}
    \caption{Target Audience Demographics and Design Implications}
    \label{table:target-audience}
\end{table}

\section{Problem Statement}

\subsection{Problem Background}

The exponential growth of academic literature --- with over 2.5 million papers published annually across 30,000+ journals --- has created a knowledge discovery crisis. Researchers spend 40--60\% of their time on non-research activities: searching for relevant papers, extracting key insights, organizing references, and collaborating with team members. Traditional tools (reference managers like Zotero/Mendeley, cloud storage like Google Drive, note-taking apps like Notion) operate in silos, forcing researchers to context-switch between 3--5 disconnected platforms daily.

\subsection{Problem Description}

Our survey of 32 respondents revealed critical pain points in current research workflows:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../response_image/8.png}
    \caption{Top Research Workflow Pain Points (Multi-Select Survey)}
    \label{fig:pain-points}
\end{figure}

\textbf{Top Pain Points (Multi-Select Responses):}

\begin{enumerate}
    \item \textbf{46.9\%} - Difficulty taking and keeping notes
    \item \textbf{40.6\%} - Hard to find specific papers later
    \item \textbf{34.4\%} - Hard to keep papers organized
    \item \textbf{28.1\%} - Syncing across devices is inconsistent
    \item \textbf{25\%} - Collaboration challenges
    \item \textbf{25\%} - Tools feel complex or overwhelming
\end{enumerate}

\textbf{Current Tool Fragmentation (Figure~\ref{fig:current-tools}):}

\begin{itemize}
    \item \textbf{34.4\%} read directly in the browser (no organization, lost tabs)
    \item \textbf{31.3\%} rely on local folders (no metadata, weak search)
    \item \textbf{31.3\%} store files in cloud drives (Drive/OneDrive --- files only, no paper context)
    \item \textbf{28.1\%} do not use any specific tool
    \item \textbf{15.6\%} use Zotero (citation manager; limited modern collaboration)
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../response_image/6.png}
    \caption{Current Tools Used by Researchers (Multi-Select Survey)}
    \label{fig:current-tools}
\end{figure}

\subsection{Problem Reasoning}

The fragmented tool landscape stems from three fundamental market failures:

\begin{enumerate}
    \item \textbf{Legacy Tool Stagnation}: Traditional reference managers (Zotero, Mendeley) were designed in the pre-AI era (2006--2011). Their outdated interfaces and lack of modern features (semantic search, AI summaries, real-time collaboration) fail to meet Gen-Z expectations shaped by tools like Notion, Figma, and ChatGPT.

    \item \textbf{Lack of Integrated Workflows}: Researchers cobble together 3--5 disconnected tools:
          \begin{itemize}
              \item Google Drive for storage
              \item Zotero for citations
              \item Notion for notes
              \item Email for collaboration
              \item ChatGPT for summaries (copy-paste PDFs manually)
          \end{itemize}
          This creates context-switching overhead, data silos, and cognitive load that reduces research velocity by 30--50\%.

    \item \textbf{AI Integration Gap}: Despite the transformer revolution (2017--2024), existing research tools remain fundamentally unchanged. Papers are still searched by keywords (not semantic meaning), summaries are manual, and citations lack context. The market lacks a platform that treats AI as a first-class citizen, not a bolt-on feature.
\end{enumerate}

extbf{Validation}: 75\% of surveyed researchers indicated ``moderate to extreme need'' for a dedicated research paper management solution (Figure~\ref{fig:need-assessment}), while current tool satisfaction averages only 3.28/5 --- indicating significant room for improvement.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../response_image/9.png}
    \caption{Need Assessment for Dedicated Research Management Solution}
    \label{fig:need-assessment}
\end{figure}

\section{Goal}

\subsection{Primary Objective}

Develop a production-ready, AI-native research paper collaboration platform that consolidates fragmented workflows into a unified hub, reducing research administrative overhead by 40--50\% while improving knowledge discovery accuracy and team collaboration efficiency.

\subsection{Specific Goals}

\begin{enumerate}
    \item \textbf{Unified Research Hub}
          \begin{itemize}
              \item Single platform integrating paper storage (S3), organization (collections/workspaces), AI insights (summaries, semantic search), annotations, and team collaboration
              \item Eliminate context-switching between 3--5 disconnected tools
              \item Target: 80\% reduction in tool fragmentation for power users
          \end{itemize}

    \item \textbf{AI-Powered Knowledge Discovery}
          \begin{itemize}
              \item Semantic search using pgvector embeddings (sub-300ms latency)
              \item AI paper summaries with 85\% time savings (validated by 82.7\% feature demand)
              \item Multi-paper chat for cross-paper insights and synthesis
              \item Deep research mode with citation graph exploration
          \end{itemize}

    \item \textbf{Real-Time Collaboration Infrastructure}
          \begin{itemize}
              \item 5-tier role-based access control (Owner → Researcher)
              \item Shared workspaces with live presence indicators
              \item Inline annotations with threading and versioning (Phase 3)
              \item Email sharing with granular permissions (view/edit)
          \end{itemize}

    \item \textbf{Modern Gen-Z UX}
          \begin{itemize}
              \item Dark mode, glassmorphism, responsive mobile-first design
              \item OAuth (Google/GitHub) with JWT session management
              \item Sub-second interactions, optimistic updates, skeleton loaders
              \item WCAG 2.1 AA accessibility compliance
          \end{itemize}

    \item \textbf{Enterprise-Grade Scalability}
          \begin{itemize}
              \item SOC 2 certification roadmap, SSO/SAML support
              \item API access for integrations (Overleaf, MS Word, browser extensions)
              \item Stripe billing with tiered pricing (\$0/\$9.99/\$29.99/Enterprise)
              \item Performance monitoring with 99.5\% uptime SLA
          \end{itemize}
\end{enumerate}

\subsection{Success Metrics (KPIs)}

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|p{4cm}|p{6cm}|}
        \hline
        \textbf{Metric}                   & \textbf{Target} & \textbf{Measurement Method}                         \\
        \hline
        User Adoption                     &
        1,000 beta users (6 months)       &
        Registration analytics, UIU campus penetration (\textasciitilde{}60\% survey base, incl. duplicate entry) \\
        \hline
        Feature Engagement                &
        60\% weekly active on AI features &
        Track semantic search, AI summaries, multi-paper chat usage                                               \\
        \hline
        Time Savings                      &
        40\% reduction in research admin  &
        User surveys, session duration analytics before/after onboarding                                          \\
        \hline
        Collaboration Uptake              &
        30\% users in shared workspaces   &
        Workspace creation rate, team member invitation acceptance                                                \\
        \hline
        Revenue (Phase 7)                 &
        \$50K ARR (Year 1)                &
        Stripe dashboard, Pro tier conversion rate (5--10\% target)                                               \\
        \hline
        Satisfaction Score                &
        4.5/5 (vs. 3.28/5 current)        &
        In-app NPS surveys, feature feedback forms                                                                \\
        \hline
    \end{tabular}
    \caption{Key Performance Indicators and Success Metrics}
    \label{table:success-metrics}
\end{table}

\section{System Development Life Cycle (SDLC)}

ScholarFlow follows an \textbf{Agile-Iterative SDLC} with 7 phased rollouts, balancing rapid MVP delivery (Phases 1--3) with long-term scalability (Phases 4--7). This approach enables early user feedback loops, incremental feature validation, and risk mitigation through modular architecture.

\subsection{Development Methodology}

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|l|p{10cm}|}
        \hline
        \textbf{Phase}                   & \textbf{Methodology Characteristics}                                                                                              \\
        \hline
        \textbf{Phase 1--3 (MVP)}        &
        \textbf{Sprint-Based Agile} (2-week sprints), Daily standups, Continuous deployment to staging, Feature flags for A/B testing, User feedback loops every 2 sprints   \\
        \hline
        \textbf{Phase 4--5 (Scale)}      &
        \textbf{Kanban Flow} (continuous delivery), Performance profiling every release, Database migration staging, Blue-green deployment for zero-downtime updates         \\
        \hline
        \textbf{Phase 6--7 (Enterprise)} &
        \textbf{Hybrid Agile-Waterfall} (regulatory compliance requires upfront planning), SOC 2 audit checkpoints, Penetration testing, Load testing (10K concurrent users) \\
        \hline
    \end{tabular}
    \caption{SDLC Methodology by Development Phase}
    \label{table:sdlc-methodology}
\end{table}

% Roadmap table removed for brevity - detailed in project documentation

\subsection{SDLC Stages Detail}

\subsubsection{1. Requirements Analysis}

\begin{itemize}
    \item \textbf{Survey-Driven Requirements}: 32-response survey with 21 questions across demographics, feature priorities, and adoption intent
    \item \textbf{Competitive Analysis}: Feature matrix comparing ScholarFlow vs. Zotero, Mendeley, Paperpile, Paperpal (20+ features)
    \item \textbf{Stakeholder Interviews}: Conversations with UIU researchers, professors, and research assistants
    \item \textbf{Output}: This SRS document, feature prioritization matrix (P0/P1/P2), technical feasibility assessment
\end{itemize}

\subsubsection{2. System Design}

\begin{itemize}
    \item \textbf{Architecture}: Microservices-ready monorepo (Next.js frontend, Express.js backend, PostgreSQL + pgvector)
    \item \textbf{Database Design}: Prisma ORM with 15+ tables (User, Paper, Collection, Workspace, Annotation, etc.), TypedSQL for raw queries
    \item \textbf{UI/UX Design}: Figma prototypes (102 pages), ShadCN component library, design system (colors, typography, spacing)
    \item \textbf{Security Design}: JWT authentication, rate limiting, CORS, input sanitization, secure password reset flows
\end{itemize}

\subsubsection{3. Implementation}

\begin{itemize}
    \item \textbf{Tech Stack}: TypeScript 100\%, Next.js 15 (App Router), Express.js, Prisma ORM, Zod validation, Redux Toolkit Query
    \item \textbf{Code Quality}: ESLint + Prettier, Husky pre-commit hooks, TypeScript strict mode, 80\%+ test coverage target
    \item \textbf{Deployment}: Vercel (frontend), Railway/Render (backend), AWS S3 (file storage), Neon/Supabase (PostgreSQL)
    \item \textbf{Monitoring}: Health check endpoints, performance tracking middleware, error logging (Sentry planned)
\end{itemize}

\subsubsection{4. Testing}

\begin{itemize}
    \item \textbf{Unit Tests}: Jest + React Testing Library for components, Supertest for API endpoints
    \item \textbf{Integration Tests}: OAuth flows, paper upload pipeline, AI service integration, Stripe webhooks
    \item \textbf{E2E Tests}: Playwright for critical user journeys (signup → upload → search → export)
    \item \textbf{Performance Tests}: Load testing (Apache JMeter), database query profiling, semantic search latency benchmarks
\end{itemize}

\subsubsection{5. Deployment}

\begin{itemize}
    \item \textbf{CI/CD Pipeline}: GitHub Actions for automated testing, linting, type-checking, and deployment
    \item \textbf{Staging Environment}: Pre-production environment for final validation before production releases
    \item \textbf{Feature Flags}: LaunchDarkly/Flagsmith for gradual feature rollouts and A/B testing
    \item \textbf{Database Migrations}: Prisma Migrate with rollback strategies, schema versioning
\end{itemize}

\subsubsection{6. Maintenance \& Monitoring}

\begin{itemize}
    \item \textbf{Monitoring}: Health checks (/api/health, /api/health/detailed), response time tracking, uptime monitoring
    \item \textbf{Error Tracking}: Comprehensive error boundaries, retry logic, Sentry integration (Phase 4)
    \item \textbf{User Feedback}: In-app feedback forms, NPS surveys, feature request voting (Phase 5)
    \item \textbf{Iterative Improvements}: Bi-weekly sprint retrospectives, continuous performance optimization
\end{itemize}
